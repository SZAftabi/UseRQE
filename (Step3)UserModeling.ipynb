{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SZAftabi/UseRQE/blob/main/(Step3)UserModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfhcCzczV-Gk"
      },
      "source": [
        "<center> <font size='6'> ðŸ’Ÿ <b> UseRQE </b> ðŸ’Ÿ </font> <br> </center>\n",
        "<center>Recognizing Question Entailment with User Background-knowledge Modeling <br> </center> <center> <font size='4' color='red'> <b> Step (3) </b> User background-knowledge modeling </font> </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEdGg56FWsWV"
      },
      "source": [
        "# ðŸ˜Ž **Mount the drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KphPULSmdv_F"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiXiD59XAIjV"
      },
      "outputs": [],
      "source": [
        "Drive_path = \"/content/drive/MyDrive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl4_G7CblsQj"
      },
      "source": [
        "# ðŸ˜Ž **1. Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXoy3AYTBIr3"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U transformers                                                 # ==4.31.0\n",
        "!pip install -q torchmetrics\n",
        "!pip install -q pytorch_lightning\n",
        "!pip install -q bitsandbytes\n",
        "!pip install -q -U peft                                                         # ==0.4.0\n",
        "!pip install -q accelerate                                                      # ==0.21.0\n",
        "!pip install -q trl\n",
        "!pip install -q tensorboard\n",
        "!pip install -q datasets\n",
        "!pip install -q rouge\n",
        "!pip install -q bert-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiX1X7U3USQu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import warnings\n",
        "import nltk\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "nltk.download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import bitsandbytes as bnb\n",
        "import pytorch_lightning as pl\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSacSak3No1M"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade huggingface-hub\n",
        "# !pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyZM5lzmASd0"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning import Callback\n",
        "from tensorboard import notebook\n",
        "\n",
        "from torchmetrics import MetricCollection\n",
        "from torchmetrics.text.bert import BERTScore\n",
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "from torchmetrics.classification import (\n",
        "    BinaryAccuracy,\n",
        "    BinaryPrecision,\n",
        "    BinaryRecall,\n",
        "    BinaryF1Score\n",
        "    )\n",
        "\n",
        "from peft import (\n",
        "    TaskType,\n",
        "    PeftModel,\n",
        "    PeftConfig,\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    AutoPeftModelForCausalLM,\n",
        "    prepare_model_for_kbit_training,\n",
        "    )\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    )\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from nltk.tokenize import word_tokenize\n",
        "from typing import Optional\n",
        "from tqdm import tqdm\n",
        "from bert_score import BERTScorer\n",
        "from rouge import Rouge\n",
        "from statistics import mean\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "tqdm.pandas()\n",
        "warnings.filterwarnings('ignore')\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rUff6oUlvrH"
      },
      "source": [
        "# ðŸ˜Ž **2. Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbyTvzmMvGiF"
      },
      "outputs": [],
      "source": [
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "betBMcTQvTkW"
      },
      "outputs": [],
      "source": [
        "def get_tg_prompt(_question, _tags = None):\n",
        "  system_prompt = 'You are a Tag Generator. Respond only with a list of tags; do not include any additional text or explanations.'\n",
        "  user_prompt = f'''Please generate at least 5 tags for the provided question. Tags can include multi-word phrases if appropriate and should help hierarchically categorize the question's topics.\n",
        "### Question:\n",
        "{_question}\n",
        "### Tags:\n",
        "'''\n",
        "  prompt = f\"{B_INST} {B_SYS}{system_prompt}{E_SYS}{user_prompt} {E_INST}\\n\\n\"\n",
        "  if _tags: prompt += f'{_tags}</s>'\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5Ae4n-vgUdR"
      },
      "outputs": [],
      "source": [
        "def get_response_index(_input_ids, _task):\n",
        "  _index = None\n",
        "  _skip_tokens = None\n",
        "  if _task == 'RQE':\n",
        "    _index = 2\n",
        "    _skip_tokens = 10\n",
        "  if _task == 'SUM':\n",
        "    _index = 1\n",
        "    _skip_tokens = 11\n",
        "  if _task == 'TG':\n",
        "    _index = 1\n",
        "    _skip_tokens = 10\n",
        "  hashtags_indexes = [i for i, n in enumerate(_input_ids) if n == 29937]\n",
        "  if len(hashtags_indexes) > _index:\n",
        "    return [i for i, n in enumerate(_input_ids) if n == 29937][_index] + _skip_tokens\n",
        "  elif _task == 'RQE':\n",
        "    return 0\n",
        "  else:\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cIoAmSFvXVq"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(data, is_eval):\n",
        "  promp = None\n",
        "  if is_eval: prompt = get_tg_prompt(data['text'])\n",
        "  else: prompt = get_tg_prompt(data['text'], data['tags'])\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FsBMB31t0M8"
      },
      "source": [
        "# ðŸ˜Ž **3. LLama2-TG**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDEShe_LPvZu"
      },
      "source": [
        "## ðŸŒ» **3.1. hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeMlef8LBt4X"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ScriptArguments:\n",
        "    max_seq_length: Optional[int] = field(\n",
        "        default = 512,\n",
        "        metadata = {\"help\": \"maximum input sequence length\"}\n",
        "      )\n",
        "    max_new_tokens: Optional[int] = field(\n",
        "        default = 30,\n",
        "        metadata = {\"help\": \"the maximum number of new tokens in the generated sequences (test step)\"}\n",
        "      )\n",
        "\n",
        "parser = HfArgumentParser(ScriptArguments)\n",
        "script_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)[0]\n",
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7REjn7V2KN7"
      },
      "source": [
        "## ðŸŒ» **3.2. data preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zvhk7mmiFfo"
      },
      "outputs": [],
      "source": [
        "class TGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len, is_eval):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.is_eval = is_eval\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      row_data = self.data.iloc[index]\n",
        "      prompt = generate_prompt(row_data, self.is_eval)\n",
        "      prompt_encoding = self.tokenizer(\n",
        "          prompt,\n",
        "          max_length = self.max_len,\n",
        "          padding = 'max_length',\n",
        "          truncation = True,\n",
        "          add_special_tokens = True,\n",
        "          return_tensors = 'pt',\n",
        "      )\n",
        "      input_ids = prompt_encoding['input_ids'].squeeze()\n",
        "      attention_mask = prompt_encoding['attention_mask'].squeeze()\n",
        "      if self.is_eval == False:\n",
        "        response_index = get_response_index(input_ids, 'TG')\n",
        "        if response_index:\n",
        "          labels = torch.cat(\n",
        "              (torch.full((response_index,), -100),\n",
        "               input_ids[response_index:])\n",
        "              ).squeeze()\n",
        "        else:\n",
        "          print('response_index not found')\n",
        "      else:\n",
        "        labels = self.tokenizer(\n",
        "            row_data['tags'] + '</s>',\n",
        "            add_special_tokens = False,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        labels = labels['input_ids'].squeeze()\n",
        "      return {\n",
        "          'input_ids': input_ids,\n",
        "          'attention_mask': attention_mask,\n",
        "          'labels': labels\n",
        "      }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBnjaoEvKMhw"
      },
      "source": [
        "## ðŸŒ» **3.3. load model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHM7MIBoA16n"
      },
      "outputs": [],
      "source": [
        "BaseModel= AutoModelForCausalLM.from_pretrained(\n",
        "    f\"{Drive_path}llama-2-7b-chat-hf\",\n",
        "    device_map={\"\": 0},\n",
        "    offload_folder=\"offload\",\n",
        "    offload_state_dict = True,\n",
        "    # load_in_8bit = True,\n",
        "    )\n",
        "\n",
        "address = f\"/content/drive/MyDrive/UseRQE/TG/TG-Adapters/LLama-TG10\"\n",
        "print(\"\\n Loading model from \", address, \"\\n\")\n",
        "config = PeftConfig.from_pretrained(address)\n",
        "fModel= PeftModel.from_pretrained(BaseModel,address,device_map={\"\": 0})\n",
        "fModel = fModel.merge_and_unload()\n",
        "\n",
        "print(\"\\n Model successfully loded from \", address, \"\\n\")\n",
        "print(fModel)\n",
        "print(fModel.config)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    script_args.model_name,\n",
        "    padding_side='left'\n",
        "    )\n",
        "\n",
        "tokenizer.pad_token_id = 0\n",
        "fModel.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5_azJeDaElC"
      },
      "source": [
        "## ðŸŒ» **3.4. test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-c54lijLeBL"
      },
      "outputs": [],
      "source": [
        "def test_step(test_dl):\n",
        "  testOutputs = []\n",
        "\n",
        "  for batch in test_dl:\n",
        "    input_ids = batch['input_ids'].cuda()\n",
        "    attention_mask = batch['attention_mask'].cuda()\n",
        "\n",
        "    generated_txts_ids = fModel.generate(\n",
        "        input_ids = input_ids,\n",
        "        max_new_tokens = script_args.max_new_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=0.97\n",
        "        ).squeeze()\n",
        "\n",
        "    generated_txts = tokenizer.decode(\n",
        "        generated_txts_ids[get_response_index(generated_txts_ids, 'TG'):],\n",
        "        skip_special_tokens = False,\n",
        "        clean_up_tokenization_spaces = True\n",
        "        )\n",
        "\n",
        "    testOutputs.append(generated_txts[:-4])\n",
        "\n",
        "  return testOutputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwJR39m-yVp0"
      },
      "source": [
        "# ðŸ˜Ž **4. Modeling user knowledge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvej4Qja0DLv"
      },
      "source": [
        "## ðŸŒ» **4.1. Find users' history**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea0uhG_5AVeA"
      },
      "outputs": [],
      "source": [
        "data_path_LLama = f\"{Drive_path}RQE_Data_With_Both_uesrid.pkl\"\n",
        "MyData_LLama = pd.read_pickle(data_path_LLama)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='65001'), 'body_Q2']='So when I launch Minecraft, before it finishes loading, it crashes. I do not understand what is going on. Could someone help me? Here is my crash report:'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='36896'), 'body_Q2']='How do I type the infinity symbol in MacTex'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='3031'), 'body_Q2']='Run time error for GP objects'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q1']=='') & (MyData_LLama['userid_Q2']=='65001'), 'body_Q1']='Misplaced allignment tab character line 53'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q1']=='') & (MyData_LLama['userid_Q2']=='16188'), 'body_Q1']='How to Export this animation as a gif file for powerpoint presentation'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q1']=='') & (MyData_LLama['userid_Q2']=='24829'), 'body_Q1']='why does rotation style work on actual coordinates and not variables in tikz 3d plot'\n",
        "\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='50615'), 'body_Q2']='How set a table in margin'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='23835'), 'body_Q2']='Latex equation positioning problem'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='14524'), 'body_Q2']='Chapter comment with regulation'\n",
        "MyData_LLama.loc[(MyData_LLama['body_Q2']=='') & (MyData_LLama['userid_Q2']=='50823'), 'body_Q2']='minipage goes beyond right margin'"
      ],
      "metadata": {
        "id": "MzZFTfRSTkMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tuLtQdJPjvd"
      },
      "outputs": [],
      "source": [
        "user_history_df = pd.DataFrame(columns=['userid', 'historyCount', 'historyIDs', 'history'])\n",
        "for index, row in MyData_LLama.iterrows():\n",
        "    user_id = row['userid_Q1']\n",
        "    forum_name = row['forum_x']\n",
        "\n",
        "    AA = (MyData_LLama[\n",
        "        (MyData_LLama['userid_Q1'] == user_id) & (MyData_LLama['forum_x'] == forum_name)\n",
        "        ][['id_Q1', 'body_Q1']])\n",
        "    AA.rename(\n",
        "        columns={'id_Q1': 'QuestionID', 'body_Q1': 'QuestionBody'},\n",
        "        inplace=True\n",
        "        )\n",
        "    BB = (MyData_LLama[\n",
        "        (MyData_LLama['userid_Q2'] == user_id) & (MyData_LLama['forum_y'] == forum_name)\n",
        "        ][['id_Q2', 'body_Q2']])\n",
        "    BB.rename(\n",
        "        columns={'id_Q2': 'QuestionID', 'body_Q2': 'QuestionBody'},\n",
        "        inplace=True\n",
        "        )\n",
        "    user_history = pd.concat([AA, BB])\n",
        "    user_history = user_history.drop_duplicates(subset=['QuestionID'])\n",
        "\n",
        "    user_history_str = ', '.join(user_history['QuestionID'].astype(str))\n",
        "    user_history_body_str = ', '.join(user_history['QuestionBody'].astype(str))\n",
        "\n",
        "    user_history_df = pd.concat(\n",
        "        [user_history_df, pd.DataFrame({'userid': [user_id],\n",
        "                                        'forum': [forum_name],\n",
        "                                        'historyCount': len(user_history),\n",
        "                                        'historyIDs': [user_history_str],\n",
        "                                        'history': [user_history_body_str]})\n",
        "        ], ignore_index=True)\n",
        "\n",
        "user_history_df_filepath = f\"{Drive_path}UseRQE/TG/user_history_df.pkl\"\n",
        "user_history_df.to_pickle(user_history_df_filepath)\n",
        "display(user_history_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4xcLhiaZHnl"
      },
      "source": [
        "## ðŸŒ» **4.2. Modeling User knowledge**\n",
        "(using LLama-TG) Generate Tags for user's questions in his/her history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJLU-D82XFYb"
      },
      "outputs": [],
      "source": [
        "user_history_df_filepath = f\"{Drive_path}UseRQE/TG/user_history_df.pkl\"\n",
        "user_history_df = pd.read_pickle(user_history_df_filepath)\n",
        "user_history_df2 = user_history_df.drop_duplicates(subset=[\"userid\", 'forum'], keep='first')\n",
        "display(user_history_df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFxtAa1zhiWx"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "fModel.eval()\n",
        "user_history_df2['generated_tags'] = None\n",
        "\n",
        "for index, row in user_history_df2.iterrows():\n",
        "    history = row['history']\n",
        "    history_questions = pd.DataFrame(history.split(', '), columns=['text'])\n",
        "    history_questions['tags'] = \"\"\n",
        "    historytags = []\n",
        "\n",
        "    data = TGDataset(history_questions, tokenizer, 512, is_eval=True)\n",
        "    DL = torch.utils.data.DataLoader(\n",
        "            data, sampler = torch.utils.data.SequentialSampler(data),\n",
        "            batch_size= 1, num_workers=8\n",
        "        )\n",
        "    historytags = test_step(DL)\n",
        "    user_history_df2.at[index, 'generated_tags']= ' -- '.join(historytags)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "user_history_df2_filepath = f\"{Drive_path}UseRQE/TG/user_history_gen_tags.pkl\"\n",
        "user_history_df2.to_pickle(user_history_df2_filepath)\n",
        "display(user_history_df2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_history_df2['generated_tags'] = user_history_df2['generated_tags'].str.replace('/', '')"
      ],
      "metadata": {
        "id": "EMAbGqUXpcif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5ZvxSALHFvr"
      },
      "outputs": [],
      "source": [
        "user_history_df['generated_tags'] = None\n",
        "user_history_df\n",
        "\n",
        "for index, row in user_history_df.iterrows():\n",
        "  ui = row['userid']\n",
        "  fr = row['forum']\n",
        "  row2 = user_history_df2[(user_history_df2['userid']==ui) & (user_history_df2['forum']==fr)]\n",
        "  user_history_df.at[index, 'generated_tags'] = (', '.join((row2['generated_tags'].item()).split(' -- ')))\n",
        "\n",
        "display(user_history_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADgm1gUB18Xh"
      },
      "source": [
        "clean redundant tags and sort them based on their frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvW1waNLMI6r"
      },
      "outputs": [],
      "source": [
        "def process_row(row):\n",
        "    tags_series = pd.Series(row['generated_tags'].split(', ')).explode()\n",
        "    tag_counts = tags_series.value_counts()\n",
        "    sorted_tags = tag_counts.index.tolist()\n",
        "    top_20_tags = sorted_tags[:20]\n",
        "    result = ', '.join(top_20_tags)\n",
        "    return result\n",
        "\n",
        "user_history_df['generated_tags'] = user_history_df.apply(process_row, axis=1)\n",
        "user_history_df_filepath = f\"{Drive_path}UseRQE/TG/user_history_T20_gen_tags.pkl\"\n",
        "user_history_df.to_pickle(user_history_df_filepath)\n",
        "display(user_history_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhCFQ3z2TA_F"
      },
      "outputs": [],
      "source": [
        "data_path_LLama = f\"{Drive_path}RQE_Data_With_Both_uesrid.pkl\"\n",
        "MyData_LLama = pd.read_pickle(data_path_LLama)\n",
        "MyData_LLama['U_Background_kn'] = user_history_df['generated_tags']\n",
        "MyData_LLama_filepath = f\"{Drive_path}UseRQE/TG/RQE_Data_With_Both_uesrid_T20_UK.pkl\"\n",
        "MyData_LLama.to_pickle(MyData_LLama_filepath)\n",
        "MyData_LLama"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}